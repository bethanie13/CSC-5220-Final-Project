{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mary Adkisson, Calen Kimmell, and Bethanie Williams\n",
    "### CSC 5220 Final Project: Malware Detection\n",
    "### Neural Networks and Support Vector Machine\n",
    "### November 23, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries we will use\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas.plotting import scatter_matrix\n",
    "from scipy import stats\n",
    "import seaborn as sb\n",
    "mpl.rcParams['figure.figsize'] = (12, 8)\n",
    "import time\n",
    "\n",
    "# import modules from sklearn\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_blobs  # many libraries form sklearn\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Other machine learning modules\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score  # many libraries form sklearn\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "legitimate\n",
      "0    140849\n",
      "1     75503\n",
      "dtype: int64\n",
      "            ID  Machine  SizeOfOptionalHeader  Characteristics  \\\n",
      "0            1      332                   224             8450   \n",
      "1            2      332                   224              258   \n",
      "2            3      332                   224             8450   \n",
      "3            4      332                   224             8450   \n",
      "4            5      332                   224             8226   \n",
      "...        ...      ...                   ...              ...   \n",
      "216347  216348      332                   224              258   \n",
      "216348  216349      332                   224            33167   \n",
      "216349  216350      332                   224              258   \n",
      "216350  216351      332                   224            33166   \n",
      "216351  216352      332                   224              258   \n",
      "\n",
      "        MajorLinkerVersion  MinorLinkerVersion  SizeOfCode  \\\n",
      "0                        8                   0       16896   \n",
      "1                        9                   0       84480   \n",
      "2                        8                   0        4608   \n",
      "3                       10                   0      108544   \n",
      "4                       48                   0      513024   \n",
      "...                    ...                 ...         ...   \n",
      "216347                  11                   0      205824   \n",
      "216348                   2                  25       37888   \n",
      "216349                  10                   0      118272   \n",
      "216350                   2                  25       49152   \n",
      "216351                  11                   0      111616   \n",
      "\n",
      "        SizeOfInitializedData  SizeOfUninitializedData  AddressOfEntryPoint  \\\n",
      "0                        8192                        0                16947   \n",
      "1                       25600                        0                10973   \n",
      "2                        3584                        0                 6452   \n",
      "3                       15872                        0               105021   \n",
      "4                        2048                        0               520922   \n",
      "...                       ...                      ...                  ...   \n",
      "216347                 223744                        0               123291   \n",
      "216348                 185344                        0                40000   \n",
      "216349                 380416                        0                59610   \n",
      "216350                  16896                        0                51216   \n",
      "216351                 468480                        0                22731   \n",
      "\n",
      "        ...  ExportNb  ResourcesNb  ResourcesMeanEntropy  ResourcesMinEntropy  \\\n",
      "0       ...        31            1              3.492126             3.492126   \n",
      "1       ...         2            1              3.486827             3.486827   \n",
      "2       ...         3            1              3.517270             3.517270   \n",
      "3       ...       105            2              3.270559             3.034188   \n",
      "4       ...         0            1              3.420977             3.420977   \n",
      "...     ...       ...          ...                   ...                  ...   \n",
      "216347  ...         0            7              4.122736             1.370260   \n",
      "216348  ...         0           26              3.377663             2.031619   \n",
      "216349  ...         0           22              6.825406             2.617026   \n",
      "216350  ...         0           10              3.421627             2.060964   \n",
      "216351  ...         0            4              4.407252             1.980482   \n",
      "\n",
      "        ResourcesMaxEntropy  ResourcesMeanSize  ResourcesMinSize  \\\n",
      "0                  3.492126         864.000000               864   \n",
      "1                  3.486827         892.000000               892   \n",
      "2                  3.517270         952.000000               952   \n",
      "3                  3.506931        1032.000000               972   \n",
      "4                  3.420977         954.000000               954   \n",
      "...                     ...                ...               ...   \n",
      "216347             7.677091       14900.714286                16   \n",
      "216348             5.050074        6905.846154                44   \n",
      "216349             7.990487       14981.909091                48   \n",
      "216350             4.739744         601.600000                16   \n",
      "216351             6.115374       96625.000000                20   \n",
      "\n",
      "        ResourcesMaxSize  LoadConfigurationSize  VersionInformationSize  \n",
      "0                    864                     72                       0  \n",
      "1                    892                     72                       0  \n",
      "2                    952                     72                       0  \n",
      "3                   1092                     72                       0  \n",
      "4                    954                      0                       0  \n",
      "...                  ...                    ...                     ...  \n",
      "216347             81654                     72                       0  \n",
      "216348             67624                      0                      15  \n",
      "216349             22648                     72                      14  \n",
      "216350              2216                      0                       0  \n",
      "216351            318464                     72                       0  \n",
      "\n",
      "[216352 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "num_cols = range(0,57)\n",
    "dataset = read_csv('Kaggle-data.csv', header= 0, usecols= num_cols) # importing csv\n",
    "#Dropped the md5 hash column \n",
    "dataset = dataset.drop(['md5'], axis=1)\n",
    "#Get the y values into a separate dataframe\n",
    "y_vals = dataset.legitimate\n",
    "# shows us the number of instances (rows) that belong to each class\n",
    "print(dataset.groupby('legitimate').size())  \n",
    "#Drop the y values from the original dataframe \n",
    "dataset = dataset.drop(['legitimate'], axis=1)\n",
    "print(dataset)  # you will need to change the file directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Normalize and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vals = dataset.iloc[:,:].values #\n",
    "y_vals = y_vals.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler()\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "print(scaler.fit(X_vals))\n",
    "MinMaxScaler()\n",
    "max_data = scaler.data_max_\n",
    "norm_data = scaler.transform(X_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-Train Shape: (138464, 55)\n",
      "y train Shape: (138464,)\n",
      "X-Test Shape: (43271, 55)\n",
      "y test shape: (43271,)\n",
      "X-Validation Shape: (34617, 55)\n",
      "y Validation shape: (34617,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(norm_data, y_vals, test_size = 0.2, random_state = 0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state = 0)\n",
    "print(\"X-Train Shape:\", X_train.shape)\n",
    "print(\"y train Shape:\", y_train.shape)\n",
    "print(\"X-Test Shape:\", X_test.shape)\n",
    "print(\"y test shape:\", y_test.shape)\n",
    "print(\"X-Validation Shape:\", X_val.shape)\n",
    "print(\"y Validation shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: SVM Model with Kernel = 'Linear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]The confusion matrix is: \n",
      " [[27865   274]\n",
      " [  266 14866]]\n",
      "The precision score is: 0.9819022457067371\n",
      "The recall score is: 0.9824213587100185\n",
      "The F1 score is: 0.982161733615222\n",
      "The accuracy score is: 0.9875205102724689\n",
      "The ROC-AUC score is: 0.9863419917683857\n",
      "Time to train 124.8690 seconds\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear', verbose=2) # Linear Kernel\n",
    "tic = time.perf_counter()\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "toc = time.perf_counter()\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "confuse_matrix =confusion_matrix(y_test.flatten(), y_pred)\n",
    "precision = precision_score(y_test.flatten(), y_pred)\n",
    "recall = recall_score(y_test.flatten(), y_pred)\n",
    "F1 = f1_score(y_test.flatten(), y_pred)\n",
    "accuracy = accuracy_score(y_test.flatten(), y_pred)\n",
    "roc_auc = roc_auc_score(y_test.flatten(), y_pred)\n",
    "parameters = clf.coef_\n",
    "\n",
    "print('The confusion matrix is: \\n {}'.format(confuse_matrix))\n",
    "print('The precision score is: {}'.format(precision))\n",
    "print('The recall score is: {}'.format(recall))\n",
    "print('The F1 score is: {}'.format(F1))\n",
    "print('The accuracy score is: {}'.format(accuracy))  # the results of the built in functions on scikit learn\n",
    "print('The ROC-AUC score is: {}'.format(roc_auc))   # are VERY VERY similar to my results above\n",
    "print(f\"Time to train {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: SVM Model with Kernel = 'RBF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]The confusion matrix is: \n",
      " [[28030   109]\n",
      " [  212 14920]]\n",
      "The precision score is: 0.9927473551134474\n",
      "The recall score is: 0.9859899550621201\n",
      "The F1 score is: 0.989357116806472\n",
      "The accuracy score is: 0.9925816366619676\n",
      "The ROC-AUC score is: 0.9910581638560894\n",
      "Time to train 101.3249 seconds\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='rbf',verbose=2) # radial basis Kernel\n",
    "tic = time.perf_counter()\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "toc = time.perf_counter()\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "confuse_matrix =confusion_matrix(y_test.flatten(), y_pred)\n",
    "precision = precision_score(y_test.flatten(), y_pred)\n",
    "recall = recall_score(y_test.flatten(), y_pred)\n",
    "F1 = f1_score(y_test.flatten(), y_pred)\n",
    "accuracy = accuracy_score(y_test.flatten(), y_pred)\n",
    "roc_auc = roc_auc_score(y_test.flatten(), y_pred)\n",
    "# parameters = clf.coef_\n",
    "\n",
    "print('The confusion matrix is: \\n {}'.format(confuse_matrix))\n",
    "print('The precision score is: {}'.format(precision))\n",
    "print('The recall score is: {}'.format(recall))\n",
    "print('The F1 score is: {}'.format(F1))\n",
    "print('The accuracy score is: {}'.format(accuracy))  # the results of the built in functions on scikit learn\n",
    "print('The ROC-AUC score is: {}'.format(roc_auc))   # are VERY VERY similar to my results above\n",
    "print(f\"Time to train {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Hyper-Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total= 1.0min\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, gamma=0.001, kernel=rbf, total= 6.9min\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ................... C=10, gamma=0.0001, kernel=rbf, total= 6.3min\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ................... C=10, gamma=0.0001, kernel=rbf, total=14.7min\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=0.001, kernel=rbf, total=  11.9s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ................... C=100, gamma=0.001, kernel=rbf, total= 2.1min\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] .................. C=100, gamma=0.0001, kernel=rbf, total= 1.0min\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] .................. C=100, gamma=0.0001, kernel=rbf, total= 6.9min\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=0.001, kernel=rbf, total=   2.5s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] .................. C=1000, gamma=0.001, kernel=rbf, total=  53.6s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] ................. C=1000, gamma=0.0001, kernel=rbf, total=  12.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] ................. C=1000, gamma=0.0001, kernel=rbf, total= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed: 42.5min finished\n"
     ]
    }
   ],
   "source": [
    "# Tuning Hyper-Parameters\n",
    "# make exhaustive grid search function to find the optimal ùê∂ and gamma values\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], # Set the parameters by cross-validation\n",
    "                     'C': [10, 100, 1000]}]\n",
    "\n",
    "scores = ['f1']\n",
    "tic = time.perf_counter()\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, scoring='%s' % score, verbose=2, cv=2)\n",
    "    clf.fit(norm_data, y_vals)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_val, clf.predict(X_val)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "    \n",
    "toc = time.perf_counter()\n",
    "print(f\"Time to optimize F1 {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate Optimal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = clf.best_params_['C']\n",
    "gamma = clf.best_params_['gamma']\n",
    "kernel = clf.best_params_['kernel']\n",
    "print(C)\n",
    "print(gamma)\n",
    "print(kernel)\n",
    "clf = svm.SVC(C = C, kernel = kernel, gamma = gamma) # radial basis Kernel\n",
    "tic = time.perf_counter()\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "toc = time.perf_counter()\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "confuse_matrix =confusion_matrix(y_test.flatten(), y_pred)\n",
    "precision = precision_score(y_test.flatten(), y_pred)\n",
    "recall = recall_score(y_test.flatten(), y_pred)\n",
    "F1 = f1_score(y_test.flatten(), y_pred)\n",
    "accuracy = accuracy_score(y_test.flatten(), y_pred)\n",
    "roc_auc = roc_auc_score(y_test.flatten(), y_pred)\n",
    "# parameters = clf.coef_\n",
    "\n",
    "print('The confusion matrix is: \\n {}'.format(confuse_matrix))\n",
    "print('The precision score is: {}'.format(precision))\n",
    "print('The recall score is: {}'.format(recall))\n",
    "print('The F1 score is: {}'.format(F1))\n",
    "print('The accuracy score is: {}'.format(accuracy))  # the results of the built in functions on scikit learn\n",
    "print('The ROC-AUC score is: {}'.format(roc_auc))   # are VERY VERY similar to my results above\n",
    "print(f\"Time to train {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
